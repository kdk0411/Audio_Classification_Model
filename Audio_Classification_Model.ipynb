{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kdk0411/Audio_Classification_Model/blob/main/Audio_Classification_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Residual Block 사용"
      ],
      "metadata": {
        "id": "Y4SIbzdRbaIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa\n",
        "import os\n",
        "import pathlib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, concatenate, Conv2D, Reshape, BatchNormalization, Activation, Add, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "# from tensorflow.keras.losses import BinaryCrossentropy\n",
        "\n",
        "# hop_length\n",
        "\n",
        "import time\n",
        "start = time.time()\n",
        "\n",
        "class AudioClassifier:\n",
        "    def __init__(self, wav_path, csv_path):\n",
        "        self.wav_path = wav_path\n",
        "        self.csv_path = csv_path\n",
        "\n",
        "    def process_data(self):\n",
        "        X_mfcc = []\n",
        "        X_mel_spec = []\n",
        "        labels = []\n",
        "        data_dir = pathlib.Path(self.wav_path)\n",
        "        all_wav_paths = sorted(list(data_dir.glob('*.wav')))\n",
        "\n",
        "        df = pd.read_csv(self.csv_path)\n",
        "        cry_audio_file = df[\"Cry_Audio_File\"]\n",
        "        label = df[\"Label\"]\n",
        "\n",
        "        max_length = 188\n",
        "\n",
        "        for wav_path_dir in all_wav_paths:\n",
        "            file_name = os.path.basename(wav_path_dir)\n",
        "            index = cry_audio_file[cry_audio_file == file_name].index[0]\n",
        "            label_value = label[index]\n",
        "\n",
        "            y, sr = librosa.load(wav_path_dir, sr=16000, duration=6)\n",
        "\n",
        "            mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "            if mfcc.shape[1] > max_length:\n",
        "                mfcc = mfcc[:, :max_length]\n",
        "\n",
        "            mel_spec = librosa.feature.melspectrogram(y=y, sr=sr)\n",
        "            mel_spec = librosa.amplitude_to_db(mel_spec, ref=np.max)\n",
        "            if mel_spec.shape[1] > max_length:\n",
        "                mel_spec = mel_spec[:, :max_length]\n",
        "\n",
        "            X_mfcc.append(mfcc)\n",
        "            X_mel_spec.append(mel_spec)\n",
        "            labels.append(label_value)\n",
        "\n",
        "        X_mfcc = np.array(X_mfcc)\n",
        "        X_mel_spec = np.array(X_mel_spec)\n",
        "        labels = np.array(labels)\n",
        "        return X_mfcc, X_mel_spec, labels\n",
        "\n",
        "    def preprocess_data(self):\n",
        "        X_mfcc, X_mel_spec, labels = self.process_data()\n",
        "\n",
        "        scaler_mfcc = StandardScaler()\n",
        "        scaler_mel_spec = StandardScaler()\n",
        "\n",
        "        X_mfcc_scaled = scaler_mfcc.fit_transform(X_mfcc.reshape(-1, X_mfcc.shape[-1])).reshape(X_mfcc.shape)\n",
        "        X_mel_spec_scaled = scaler_mel_spec.fit_transform(X_mel_spec.reshape(-1, X_mel_spec.shape[-1])).reshape(X_mel_spec.shape)\n",
        "\n",
        "        label_encoder = LabelEncoder()\n",
        "        labels_encoded = label_encoder.fit_transform(labels)\n",
        "        num_classes = len(label_encoder.classes_)\n",
        "\n",
        "        return X_mfcc_scaled, X_mel_spec_scaled, labels_encoded, label_encoder, num_classes\n",
        "\n",
        "train_csv_path = \"/content/drive/MyDrive/Baby_Sound/Hungry/Classificant_Audio_data/New_train_Audio.csv\"\n",
        "train_data_dir = \"/content/drive/MyDrive/Baby_Sound/Hungry/Classificant_Audio_data\"\n",
        "\n",
        "test_csv_path = \"/content/drive/MyDrive/Baby_Sound/Hungry/Classificant_Audio_data_test/test_Audio_New.csv\"\n",
        "test_data_dir = \"/content/drive/MyDrive/Baby_Sound/Hungry/Classificant_Audio_data_test\"\n",
        "\n",
        "train_classifier = AudioClassifier(train_data_dir, train_csv_path)\n",
        "X_train_mfcc, X_train_mel_spec, y_train, label_encoder, num_classes = train_classifier.preprocess_data()\n",
        "\n",
        "test_classifier = AudioClassifier(test_data_dir, test_csv_path)\n",
        "X_test_mfcc, X_test_mel_spec, y_test, _, _ = test_classifier.preprocess_data()\n",
        "\n",
        "# 데이터 분할 random_state=42\n",
        "X_train_mfcc_scaled, X_val_mfcc_scaled, X_train_mel_spec_scaled, X_val_mel_spec_scaled, y_train_encoded, y_val_encoded = train_test_split(\n",
        "    X_train_mfcc, X_train_mel_spec, y_train, test_size=0.2, stratify=y_train)\n",
        "\n",
        "print(f'X_train_mfcc_scaled : {X_train_mfcc_scaled.shape}')\n",
        "print(f'X_val_mfcc_scaled : {X_val_mfcc_scaled.shape}')\n",
        "print(f'X_train_mel_spec_scaled : {X_train_mel_spec_scaled.shape}')\n",
        "print(f'X_val_mel_spec_scaled : {X_val_mel_spec_scaled.shape}')\n",
        "print(f'y_train_encoded : {y_train_encoded.shape}')\n",
        "print(f'y_val_encoded : {y_val_encoded.shape}')\n",
        "print(f'num_classes : {num_classes}')\n",
        "\n",
        "def residual_block(inputs, filters, kernel_size):\n",
        "    x = Conv2D(filters, kernel_size, padding='same')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(filters, kernel_size, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Add()([inputs, x])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "# 모델 생성\n",
        "mfcc_input = Input(shape=X_train_mfcc_scaled.shape[1:])\n",
        "mfcc_reshaped = Reshape((*X_train_mfcc_scaled.shape[1:], 1))(mfcc_input)\n",
        "mfcc_model = Conv2D(32, kernel_size=(4, 4))(mfcc_reshaped)\n",
        "mfcc_model = BatchNormalization()(mfcc_model)\n",
        "mfcc_model = LeakyReLU()(mfcc_model)\n",
        "\n",
        "# Residual Block 추가\n",
        "mfcc_model = residual_block(mfcc_model, 32, (4, 4))\n",
        "mfcc_model = residual_block(mfcc_model, 32, (4, 4))\n",
        "\n",
        "mel_spec_input = Input(shape=(X_train_mel_spec_scaled.shape[1], X_train_mel_spec_scaled.shape[2], 1))\n",
        "mel_spec_model = Conv2D(32, kernel_size=(4, 4))(mel_spec_input)\n",
        "mel_spec_model = BatchNormalization()(mel_spec_model)\n",
        "mel_spec_model = LeakyReLU()(mel_spec_model)\n",
        "\n",
        "# Residual Block 추가\n",
        "mel_spec_model = residual_block(mel_spec_model, 32, (4, 4))\n",
        "mel_spec_model = residual_block(mel_spec_model, 32, (4, 4))\n",
        "\n",
        "mfcc_model_flatten = Flatten()(mfcc_model)\n",
        "mel_spec_model_flatten = Flatten()(mel_spec_model)\n",
        "combined = concatenate([mfcc_model_flatten, mel_spec_model_flatten])\n",
        "\n",
        "common = Dense(64, activation='relu')(combined)\n",
        "# output = Dense(1, activation='sigmoid')(common)\n",
        "output = Dense(num_classes, activation='softmax')(common)\n",
        "\n",
        "learning_rate = 0.00006  # 학습률 값\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "model = Model(inputs=[mfcc_input, mel_spec_input], outputs=output)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "model.fit([X_train_mfcc_scaled, X_train_mel_spec_scaled], y_train_encoded, batch_size=16, shuffle=True, epochs=10, validation_data=([X_val_mfcc_scaled, X_val_mel_spec_scaled], y_val_encoded))\n",
        "\n",
        "# 모델 평가\n",
        "loss, accuracy = model.evaluate([X_test_mfcc, X_test_mel_spec], y_test)\n",
        "model.save('Audio_Classify_Model.h5')\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy * 100, \"%\")\n",
        "\n",
        "run_time = round(time.time() - start, 2)\n",
        "print(\"Run_time :\", run_time, \"sec\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZLQkgFvRWDm",
        "outputId": "55630cf8-5cd3-411f-b2b6-80c8384d624d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_mfcc_scaled : (334, 13, 188)\n",
            "X_val_mfcc_scaled : (84, 13, 188)\n",
            "X_train_mel_spec_scaled : (334, 128, 188)\n",
            "X_val_mel_spec_scaled : (84, 128, 188)\n",
            "y_train_encoded : (334,)\n",
            "y_val_encoded : (84,)\n",
            "num_classes : 2\n",
            "Epoch 1/10\n",
            "21/21 [==============================] - 24s 199ms/step - loss: 54.4903 - accuracy: 0.7635 - val_loss: 0.7174 - val_accuracy: 0.9762\n",
            "Epoch 2/10\n",
            "21/21 [==============================] - 2s 109ms/step - loss: 1.0360 - accuracy: 0.9880 - val_loss: 2.0578e-07 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "21/21 [==============================] - 2s 118ms/step - loss: 1.4674 - accuracy: 0.9850 - val_loss: 4.7660 - val_accuracy: 0.8333\n",
            "Epoch 4/10\n",
            "21/21 [==============================] - 2s 118ms/step - loss: 1.9323 - accuracy: 0.9760 - val_loss: 5.7710 - val_accuracy: 0.8214\n",
            "Epoch 5/10\n",
            "21/21 [==============================] - 2s 108ms/step - loss: 0.4201 - accuracy: 0.9910 - val_loss: 0.5584 - val_accuracy: 0.9881\n",
            "Epoch 6/10\n",
            "21/21 [==============================] - 2s 116ms/step - loss: 1.9513 - accuracy: 0.9820 - val_loss: 0.7638 - val_accuracy: 0.9524\n",
            "Epoch 7/10\n",
            "21/21 [==============================] - 2s 117ms/step - loss: 1.1556 - accuracy: 0.9850 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "21/21 [==============================] - 2s 109ms/step - loss: 0.4667 - accuracy: 0.9970 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "21/21 [==============================] - 2s 118ms/step - loss: 0.1063 - accuracy: 0.9970 - val_loss: 9.7077e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "21/21 [==============================] - 2s 113ms/step - loss: 0.0869 - accuracy: 0.9970 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "2/2 [==============================] - 1s 158ms/step - loss: 2.8083 - accuracy: 0.9714\n",
            "Test Loss: 2.8083226680755615\n",
            "Test Accuracy: 97.14285731315613 %\n",
            "Run_time : 109.26 sec\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1DJH3ip3piHZVJ_zN6TN0CO1oR3wZIdQb",
      "authorship_tag": "ABX9TyOLSOufg4Q9tdWi2vKCBMPw",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}