{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNBO04mUcomRvtO3+4imIOK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kdk0411/Audio_Classification_Model/blob/main/Voice_preprocessing_class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmiKxxkhwHkk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa\n",
        "import os\n",
        "import pathlib\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "class AudioClassifier:\n",
        "    def __init__(self, wav_path, csv_path):\n",
        "        self.wav_path = wav_path\n",
        "        self.csv_path = csv_path\n",
        "\n",
        "    def process_data(self):\n",
        "        X_mfcc = []\n",
        "        X_spec = []\n",
        "        labels = []\n",
        "        data_dir = pathlib.Path(self.wav_path)\n",
        "        all_wav_paths = sorted(list(data_dir.glob('*.wav')))\n",
        "\n",
        "        df = pd.read_csv(self.csv_path)\n",
        "        cry_audio_file = df[\"Cry_Audio_File\"]\n",
        "        label = df[\"Label\"]\n",
        "\n",
        "        max_length = 188\n",
        "\n",
        "        for wav_path_dir in all_wav_paths:\n",
        "            file_name = os.path.basename(wav_path_dir)\n",
        "            index = cry_audio_file[cry_audio_file == file_name].index[0]\n",
        "            label_value = label[index]\n",
        "\n",
        "            y, sr = librosa.load(wav_path_dir, sr=16000, duration=6)\n",
        "\n",
        "            mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "            if mfcc.shape[1] > max_length:\n",
        "                mfcc = mfcc[:, :max_length]\n",
        "\n",
        "            spec = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
        "            if spec.shape[1] > max_length:\n",
        "                spec = spec[:, :max_length]\n",
        "\n",
        "            X_mfcc.append(mfcc)\n",
        "            X_spec.append(spec)\n",
        "            labels.append(label_value)\n",
        "\n",
        "        X_mfcc = np.array(X_mfcc)\n",
        "        X_spec = np.array(X_spec)\n",
        "        labels = np.array(labels)\n",
        "        return X_mfcc, X_spec, labels\n",
        "\n",
        "    def preprocess_data(self):\n",
        "        X_mfcc, X_spec, labels = self.process_data()\n",
        "\n",
        "        X_spec = np.expand_dims(X_spec, axis=-1)\n",
        "\n",
        "        scaler_mfcc = StandardScaler()\n",
        "        scaler_spec = StandardScaler()\n",
        "\n",
        "        X_mfcc_scaled = scaler_mfcc.fit_transform(X_mfcc.reshape(-1, X_mfcc.shape[-1])).reshape(X_mfcc.shape)\n",
        "        X_spec_scaled = scaler_spec.fit_transform(X_spec.reshape(-1, X_spec.shape[-1])).reshape(X_spec.shape)\n",
        "\n",
        "        label_encoder = LabelEncoder()\n",
        "        labels_encoded = label_encoder.fit_transform(labels)\n",
        "\n",
        "        num_classes = len(label_encoder.classes_)\n",
        "        labels_encoded = to_categorical(labels_encoded, num_classes=num_classes)\n",
        "\n",
        "        return X_mfcc_scaled, X_spec_scaled, labels_encoded\n"
      ]
    }
  ]
}